1
00:00:00,350 --> 00:00:02,601
In this module, we're going to look at some hard problems

2
00:00:02,601 --> 00:00:04,919
that come up in the context of modular arithmetic.

3
00:00:04,919 --> 00:00:08,867
These problems are going to be the basis of the cryptosystems that we build next week.

4
00:00:08,867 --> 00:00:12,867
So first I'd like to mention that there are many easy problems in modular arithmetic.

5
00:00:12,867 --> 00:00:17,301
For example, if you give me an integer N, and you give me an  element x in ZN,

6
00:00:17,301 --> 00:00:21,368
finding the inverse of x is actually very easy using the Euclidean algorithm.

7
00:00:21,368 --> 00:00:25,234
Similarly, if you give me a prime p, and you give me some polynomial f,

8
00:00:25,234 --> 00:00:31,150
then finding an element in Zp that's a root of this polynomial is also relatively easy,

9
00:00:31,150 --> 00:00:37,334
and in fact there's an efficient algorithm that can do it in linear time in the degree of the polynomial.

10
00:00:37,334 --> 00:00:41,900
So at least for low-degree polynomials, finding roots of these polynomials modulo primes

11
00:00:41,900 --> 00:00:44,518
is actually quite easy.

12
00:00:44,518 --> 00:00:48,051
However many problems in modular arithmetic are actually quite difficult,

13
00:00:48,051 --> 00:00:54,501
and as I said, these difficult, these difficult problems form the basis of many public-key cryptosystems.

14
00:00:54,501 --> 00:00:58,135
So let's look at some classic hard problems modulo primes.

15
00:00:58,135 --> 00:01:02,867
So fix some large prime p, so think of p as some 600-digit prime,

16
00:01:02,867 --> 00:01:05,988
and let's fix some element g in (Zp)<i>.</i>

17
00:01:05,988 --> 00:01:10,258
And let's assume that the order of this element g happens to be a number q.

18
00:01:10,258 --> 00:01:16,656
Now, consider the exponentiation function that simply maps a number x to the element g^x.

19
00:01:16,656 --> 00:01:21,473
We showed in the last segment that this function is easy to compute

20
00:01:21,473 --> 00:01:26,789
using the repeated squaring algorithm, so in fact computing g^x can be done quite efficiently,

21
00:01:26,789 --> 00:01:29,257
but now let's look at the inverse question.

22
00:01:29,257 --> 00:01:35,590
So the inverse problem is basically, given g^x, now I want you to find its logarithm,

23
00:01:35,590 --> 00:01:43,957
namely the value x. As I said, over the reals, over the real numbers, given g to the x, find x is exactly the definition of

24
00:01:43,957 --> 00:01:48,973
the logarithm function, but here I ask you to find the logarithm modulo a prime p.

25
00:01:48,973 --> 00:01:53,029
So this problem is called the discrete logarithm problem, Dlog,

26
00:01:53,029 --> 00:02:00,338
and I'll say that the discrete logarithm of g to the x base g is basically the exponent x.

27
00:02:00,338 --> 00:02:08,090
So the discrete logarithm of g to the x is x, so our goal is to output some exponent x in 0 to q-2

28
00:02:08,090 --> 00:02:12,071
that happens to be the logarithm of g to the x.

29
00:02:12,071 --> 00:02:17,973
So let's look at an example. Suppose we look at the integers modulo 11,

30
00:02:17,973 --> 00:02:23,039
and here I wrote down the discrete log function in Z₁₁, base 2.

31
00:02:23,039 --> 00:02:25,856
So let's look at how this function behaves.

32
00:02:25,856 --> 00:02:31,106
So first of all, the discrete logarithm of 1 is 0, because 2 to the 0 is equal to 1.

33
00:02:31,106 --> 00:02:39,039
Similarly the discrete logarithm of 2 is 1, because 2 to the 1 is equal to 2.

34
00:02:39,039 --> 00:02:44,223
The discrete logarithm of 4 is 2, because 2 squared is equal to 4.

35
00:02:44,223 --> 00:02:48,141
The discrete logarithm of 8 is 3, because 2 cubed is equal to 8.

36
00:02:48,141 --> 00:02:52,989
And so on and so forth. So here I wrote down the discrete logarithm values for you,

37
00:02:52,989 --> 00:02:57,540
and let me ask you a puzzle: what's the discrete logarithm of 5 modulo 11?

38
00:02:57,540 --> 00:03:01,890
See if you can calculate it yourself.

39
00:03:01,890 --> 00:03:10,590
And so the answer is 4, because 2 to the 4 is equal to 16, and 16 is equal to 5 modulo 11.

40
00:03:10,590 --> 00:03:15,897
OK, so this says that the discrete logarithm base 2 of 5 is this number 4.

41
00:03:15,897 --> 00:03:21,621
Now I can tell you that the discrete logarithm function in general is actually quite difficult to compute.

42
00:03:21,621 --> 00:03:24,757
Of course for small primes, it's quite easy. You can just make a table

43
00:03:24,757 --> 00:03:29,789
and you can read off the discrete log values. But if the prime p happens to be a large number,

44
00:03:29,789 --> 00:03:34,206
say a 2000-bit number, then in fact computing the discrete log is quite difficult

45
00:03:34,206 --> 00:03:37,300
and we don't have good algorithms to do it.

46
00:03:37,300 --> 00:03:40,257
So let's define the discrete log problem more generically.

47
00:03:40,257 --> 00:03:46,312
Instead of just focusing on the group (Zp)<i>, let's abstract and look at a generic group G.</i>

48
00:03:46,312 --> 00:03:49,196
So we have a finite cyclic group with the generator g.

49
00:03:49,196 --> 00:03:54,214
All that means is that this group just consists of all the powers of g.

50
00:03:54,214 --> 00:03:59,246
So we take all the powers up to the order, in this case the order of G happens to be q,

51
00:03:59,246 --> 00:04:07,279
so we take all the powers of g, and those powers actually make up the group capital-G.

52
00:04:07,279 --> 00:04:11,347
Now we're going to say that the discrete log problem is hard in the group G

53
00:04:11,347 --> 00:04:15,547
if in fact no efficient algorithm can compute the discrete log function.

54
00:04:15,547 --> 00:04:19,130
So what do we mean by that? What we mean is if you choose a random element g

55
00:04:19,130 --> 00:04:23,659
in the group capital-G, and you choose a random exponent x,

56
00:04:23,659 --> 00:04:28,550
if I give the algorithm g and g to the x—of course I also have to give it a description of the group,

57
00:04:28,550 --> 00:04:32,749
so I gave it the description of the group G, and the order of the group,

58
00:04:32,749 --> 00:04:35,485
but the primary elements are g and g to the x—

59
00:04:35,485 --> 00:04:40,667
the probability that the algorithm will actually compute the discrete log is negligible.

60
00:04:40,667 --> 00:04:44,299
Ok, so if this is true for all efficient algorithms,

61
00:04:44,299 --> 00:04:49,035
then we say that the discrete log problem is hard in this group capital-G.

62
00:04:49,035 --> 00:04:54,068
And again, the reason we say that is because no efficient algorithm is able

63
00:04:54,068 --> 00:04:58,036
to compute discrete log with non-negligible probability.

64
00:04:58,036 --> 00:05:01,217
So as I mentioned, we have a couple of candidate examples

65
00:05:01,217 --> 00:05:03,535
for groups where discrete log is hard.

66
00:05:03,535 --> 00:05:07,368
The canonical example is (Zp)<i>, this is actually the example that Diffie and Hellman</i>

67
00:05:07,368 --> 00:05:12,600
came up with in 1974, but it turns out there are other candidate groups

68
00:05:12,600 --> 00:05:16,423
where the discrete log problem happens to be hard, and I think I already mentioned

69
00:05:16,423 --> 00:05:19,319
that one candidate is what's called the elliptic curve group,

70
00:05:19,319 --> 00:05:23,751
or rather, the set of points on an elliptic curve. I'm not going to define that here,

71
00:05:23,751 --> 00:05:27,568
but as I said, if you'd like me to talk about elliptic curve cryptography, I can do that actually

72
00:05:27,568 --> 00:05:31,634
in the very last week of the class.

73
00:05:31,634 --> 00:05:35,868
So these are two groups where the discrete log problem is in fact believed to be hard,

74
00:05:35,868 --> 00:05:40,917
but it so happens that the discrete log problem actually is harder, as far as we know,

75
00:05:40,917 --> 00:05:46,235
on elliptic curves than it is on (Zp)<i>. In other words, if you give me equal-sized problems</i>

76
00:05:46,235 --> 00:05:50,186
one set in the group (Zp)<i>, and one set in an elliptic curve group,</i>

77
00:05:50,186 --> 00:05:53,517
the problem set in the elliptic curve group is going to be much harder

78
00:05:53,517 --> 00:05:58,417
than the problem in (Zp)<i>, again assuming these two problems are of the same size.</i>

79
00:05:58,417 --> 00:06:04,202
And because the elliptic curve problem, the discrete log elliptic curve problem is harder than in (Zp)<i>,</i>

80
00:06:04,202 --> 00:06:08,267
this means that we can use smaller parameters when using elliptic curves

81
00:06:08,267 --> 00:06:12,451
than we can for (Zp)<i>, and as a result, the resulting systems with elliptic curves</i>

82
00:06:12,451 --> 00:06:15,702
are going to be more efficient, because the parameters are smaller,

83
00:06:15,702 --> 00:06:22,867
and yet the attacker's job is as hard as for a much larger prime in (Zp)<i>.</i>

84
00:06:22,867 --> 00:06:26,355
So to make that concrete, I'll tell you that in (Zp)<i>, there's what's called</i>

85
00:06:26,355 --> 00:06:30,703
a sub-exponential algorithm for discrete log. So I think I already mentioned this,

86
00:06:30,703 --> 00:06:38,720
if you have an n-bit prime, this algorithm will run in roughly cube root of n time.

87
00:06:38,720 --> 00:06:42,375
In fact there are many other terms in the exact running time of this algorithm,

88
00:06:42,375 --> 00:06:46,272
but the dominant term is cube root of the number of bits in the prime,

89
00:06:46,272 --> 00:06:49,254
so cube root of n. And because of this algorithm, you see that

90
00:06:49,254 --> 00:06:52,538
if we want the discrete log problem to be hard,

91
00:06:52,538 --> 00:06:55,377
as hard as it is to break a corresponding symmetric key,

92
00:06:55,377 --> 00:06:59,953
we have to use relatively large moduli p.

93
00:06:59,953 --> 00:07:03,987
Now in contrast, if you look at an elliptic curve group, the numbers look much better,

94
00:07:03,987 --> 00:07:08,421
and in fact on an elliptic curve group, the best algorithm for discrete log that we have

95
00:07:08,421 --> 00:07:11,984
runs in time e to the n over 2. So this is what we would call

96
00:07:11,984 --> 00:07:16,269
a proper exponential-time algorithm, because for a problem of size n,

97
00:07:16,269 --> 00:07:21,620
the running time is roughly e to the n. It's an exponential in n, not an exponential in cube root of n.

98
00:07:21,620 --> 00:07:25,819
And because the problem is so much harder, again the best algorithm we have

99
00:07:25,819 --> 00:07:29,601
actually takes exponential time, you notice that in elliptic curves we can use

100
00:07:29,601 --> 00:07:33,301
much smaller parameters and still remain secure.

101
00:07:33,301 --> 00:07:38,920
By the way, the reason the elliptic curve size is exactly twice the symmetric key size

102
00:07:38,920 --> 00:07:42,303
is exactly because of this factor of 2 in the exponent here.

103
00:07:42,303 --> 00:07:48,385
So we have to double the size of the elliptic curve for the problem to actually take e to the n time.

104
00:07:48,385 --> 00:07:52,734
And actually I made a small typo here in that this is actually supposed to be 2 to the n/2.

105
00:07:52,734 --> 00:07:56,101
But the exact base of the logarithm doesn't really matter.

106
00:07:56,101 --> 00:07:59,368
So I think I mentioned before that because the parameters are smaller with elliptic curves

107
00:07:59,368 --> 00:08:04,635
than they are with (Zp)<i>, there's a slow transition from doing crypto modulo p</i>

108
00:08:04,635 --> 00:08:08,471
to doing crypto over elliptic curves.

109
00:08:08,471 --> 00:08:11,818
And again I'll mention that if you want me to describe elliptic curves in more detail,

110
00:08:11,818 --> 00:08:14,867
I can do that at the last week of the class.

111
00:08:14,867 --> 00:08:17,702
So now that we understand what the discrete log problem is,

112
00:08:17,702 --> 00:08:20,836
let me give you a direct application of the hardness of discrete log.

113
00:08:20,836 --> 00:08:25,386
An in particular, let's build a collision-resistant hash function from the discrete log problem.

114
00:08:25,386 --> 00:08:29,434
So let's choose some group capital-G where the discrete log problem is hard.

115
00:08:29,434 --> 00:08:34,408
So if you like, you can think of capital G as the group (Zp)<i>, and let's assume</i>

116
00:08:34,408 --> 00:08:41,452
that the group capital G has prime order q. So q is some prime number that happens to be the order of G,

117
00:08:41,452 --> 00:08:45,368
the number of elements in the group capital G.

118
00:08:45,368 --> 00:08:50,267
Now to define our hash function, what we'll do is we'll choose two elements in the group capital G,

119
00:08:50,267 --> 00:08:54,651
and let's call them g and h, and then we'll define the hash function as follows:

120
00:08:54,651 --> 00:09:02,420
The hash function on input x and y will output an element in G defined as g to the x times h to the y.

121
00:09:02,420 --> 00:09:08,103
That's it. Ok. A very very simple hash function, and if you recall, we even talked about this hash function

122
00:09:08,103 --> 00:09:11,523
when we talked about compression functions before.

123
00:09:11,523 --> 00:09:15,351
I want to show you that this function capital-H is in fact collision-resistant

124
00:09:15,351 --> 00:09:22,568
in the sense that finding a collision for capital H is as hard as computing discrete log in the group capital G.

125
00:09:22,568 --> 00:09:25,802
Ok. So in particular, if you can find a collision for capital H,

126
00:09:25,802 --> 00:09:30,951
you can compute the discrete log of h base g.

127
00:09:30,951 --> 00:09:34,320
And since we said the discrete log in the group capital G is hard,

128
00:09:34,320 --> 00:09:36,906
computing the discrete log should be difficult, and therefore

129
00:09:36,906 --> 00:09:39,774
finding collisions for capital H is going to be difficult.

130
00:09:39,774 --> 00:09:44,918
Ok. So let's see how we do this. It's actually a very cute proof. What we'll do is, We'll do the following.

131
00:09:44,918 --> 00:09:47,985
Suppose we are given a collision on the function capital H.

132
00:09:47,985 --> 00:09:55,585
So we're given two distinct pairs, (x0, y0) and (x1, y1), that happen to collide on the function capital H.

133
00:09:55,585 --> 00:09:58,702
What does it mean that they collide on the function capital H? What it means is that

134
00:09:58,702 --> 00:10:04,621
if I evaluate the function capital H at (x0, y0) and (x1, y1), I'll get a collision.

135
00:10:04,621 --> 00:10:08,836
Namely I'll get an equality. Well, so now I can just do a little bit of manipulation,

136
00:10:08,836 --> 00:10:11,835
and you see that this means I just move all the g's to one side

137
00:10:11,835 --> 00:10:14,169
and all the h's to the other side, so this means that

138
00:10:14,169 --> 00:10:21,035
g to the (x0 - x1) is equal to h to the (y1 - y0), this is just simple manipulation.

139
00:10:21,035 --> 00:10:29,469
Now I can raise both sides to the power of 1/(y1 - y0). In other words I am taking the (y1 - y0)th root

140
00:10:29,469 --> 00:10:34,001
of both sides. So one side will become simply h,

141
00:10:34,001 --> 00:10:42,268
and the other side will become g to the power of this fraction, (x0 - x1) divided by (y1 - y0).

142
00:10:42,268 --> 00:10:47,518
But now look at what we just got. Basically we expressed h as g to some known power.

143
00:10:47,518 --> 00:10:52,003
Basically all we did is just division, and boom, we're done. We've just expressed h

144
00:10:52,003 --> 00:10:58,934
as g to some known power. So we've computed the discrete log of h, base g.

145
00:10:58,934 --> 00:11:01,819
So you might be wondering, what does this division in the exponent mean?

146
00:11:01,819 --> 00:11:06,304
What does it mean to divide by (y1 - y0) in the exponent?

147
00:11:06,304 --> 00:11:13,903
Well what it means is basically we compute the inverse of y1 - y0 modulo q,

148
00:11:13,903 --> 00:11:19,436
and then we multiply the result by x0 - x1. And that gives us the exponent in the clear,

149
00:11:19,436 --> 00:11:25,187
and so we've just learned the discrete log of h base g.

150
00:11:25,187 --> 00:11:31,103
So this also shows you why we wanted q to be prime: because we need to make sure that y1 - y0

151
00:11:31,103 --> 00:11:36,036
is always invertible. So in fact we know that when we work modulo prime,

152
00:11:36,036 --> 00:11:39,336
everything is invertible except for zero.

153
00:11:39,336 --> 00:11:45,803
So that actually raises a subtle point, what happens if y1 - y0 actually happens to be equal to zero?

154
00:11:45,803 --> 00:11:48,585
If that's the case, then we are not going to be able to get the discrete log, because

155
00:11:48,585 --> 00:11:52,707
we won't be able to divide by zero.

156
00:11:52,707 --> 00:11:56,420
But if you think about this for a minute, you realize, well, let's see here.

157
00:11:56,420 --> 00:12:03,770
If y1 - y0 equals 0, that means that y1 is equal to y0.

158
00:12:03,770 --> 00:12:08,570
But if y1 is equal to y0, just look at this equation here, that means that

159
00:12:08,570 --> 00:12:13,759
well, that necessarily means that x0 is also equal to x1.

160
00:12:13,759 --> 00:12:17,669
This takes you a minute to convince yourself, if y0 is equal to y1,

161
00:12:17,669 --> 00:12:24,002
basically these two terms simply cancel out, and then we get that x0 is equal to x1.

162
00:12:24,002 --> 00:12:29,402
But then if x0 is equal to x1, and y0 is equal to y1, what you gave me is not a collision.

163
00:12:29,402 --> 00:12:34,585
You simply gave me the same pair twice. So that's cheating, so that's not considered a collision,

164
00:12:34,585 --> 00:12:39,587
and therefore, you know, I don't need to find a discrete log. But if you give me a collision,

165
00:12:39,587 --> 00:12:43,435
necessarily y0 is not going to be equal to y1, and then as a result

166
00:12:43,435 --> 00:12:46,102
I'm going to get the discrete log of g base h.

167
00:12:46,102 --> 00:12:50,220
And as we said, since the discrete log is believed to be hard in the group capital G,

168
00:12:50,220 --> 00:12:56,002
this means that this very very simple function capital H must be collision resistant.

169
00:12:56,002 --> 00:13:04,240
So this is a very elegant example of a reduction from finding collisions to computing discrete log.

170
00:13:04,240 --> 00:13:06,721
I should tell you by the way that this function is not really used.

171
00:13:06,721 --> 00:13:10,073
Even though this function has a nice proof of collision resistance,

172
00:13:10,073 --> 00:13:13,961
it's not really used because it's relatively slow. Essentially, on every hash

173
00:13:13,961 --> 00:13:20,355
you have to compute two exponentiations, and that's much much much slower than, say, functions like SHA-256

174
00:13:20,355 --> 00:13:26,004
and other kind of ad hoc collision-resistant hash functions.

175
00:13:26,004 --> 00:13:30,189
OK. So that's what I wanted to say about intractable problems modulo primes.

176
00:13:30,189 --> 00:13:33,511
Now let's look at some intractable problems modulo composites.

177
00:13:33,511 --> 00:13:42,024
So here we're gonna say ahh, again let's look at, say, 1024-bit numbers, and let's define the set Z-sub-2 n.

178
00:13:42,024 --> 00:13:47,075
This is going to be the set of all integers that happen to be a product of two primes

179
00:13:47,075 --> 00:13:51,392
where those two primes are n-bit primes.

180
00:13:51,392 --> 00:13:55,984
Ok. So the 2 here corresponds to the fact that the numbers in this set

181
00:13:55,984 --> 00:14:00,659
basically have 2 prime factors, and those two prime factors are roughly the same size.

182
00:14:00,659 --> 00:14:02,875
They're both n-bit primes.

183
00:14:02,875 --> 00:14:06,292
So there are two classic intractable problems in this set.

184
00:14:06,292 --> 00:14:12,242
The first problem is if I choose a random integer in the set Z(2)(n), the problem is, factor it.

185
00:14:12,242 --> 00:14:15,326
And already this is quite a difficult problem for 1024 bits.

186
00:14:15,326 --> 00:14:18,992
And although it hasn't been done yet, it's very likely that numbers of this magnitude

187
00:14:18,992 --> 00:14:25,042
will be factored soon, and so the recommended value these days is actually to use 2048-bit numbers.

188
00:14:25,042 --> 00:14:30,308
That's still beyond our reach, and those are numbers that we still cannot factor.

189
00:14:30,308 --> 00:14:36,151
Another example of an intractable problem modulo composites is if I give you some polynomial

190
00:14:36,151 --> 00:14:41,076
that's nonlinear, if the degree is bigger than 1, and I give you some random composite

191
00:14:41,076 --> 00:14:44,544
in the set Z(2)(n), your goal is to find a root of this polynomial,

192
00:14:44,544 --> 00:14:47,542
find an x that happens to be a root of this polynomial.

193
00:14:47,542 --> 00:14:50,411
And again, we don't know how to do that; of course if the degree is equal to 1,

194
00:14:50,411 --> 00:14:54,379
that just amounts to solving linear equations, and we already know that, that's easy.

195
00:14:54,379 --> 00:14:58,729
But the minute the degree becomes nonlinear, we don't know how to solve this modulo N

196
00:14:58,729 --> 00:15:04,895
without actually first factoring the modulus, and then computing roots.

197
00:15:04,895 --> 00:15:08,495
So there are some systems, for example RSA, that depend on the hardness

198
00:15:08,495 --> 00:15:14,694
of this particular problem for specific polynomials, which we're going to see next week.

199
00:15:14,694 --> 00:15:18,312
And just as an example, I should mention that for example taking square roots

200
00:15:18,312 --> 00:15:24,961
or cube roots modulo a random composite in Z(2)(n) is believed to be difficult.

201
00:15:24,961 --> 00:15:27,413
So there's actually quite a bit known about the factoring problem.

202
00:15:27,413 --> 00:15:31,329
It's actually a very old problem. Already the Greeks were interested in factoring,

203
00:15:31,329 --> 00:15:34,961
but Gauss actually has a wonderful, wonderful quote that talks about

204
00:15:34,961 --> 00:15:38,295
the problem of factoring and the problem of primality testing.

205
00:15:38,295 --> 00:15:42,233
So in his famous dissertation from 1805, he writes:

206
00:15:42,233 --> 00:15:45,228
"The problem of distinguishing prime numbers from composite numbers"

207
00:15:45,228 --> 00:15:48,062
(this is what's called primality testing)

208
00:15:48,062 --> 00:15:51,361
"and the problem of resolving the latter" (namely composites)

209
00:15:51,361 --> 00:15:57,461
"into their prime factors is known to be one of the most important and useful in arithmetic."

210
00:15:57,461 --> 00:16:01,408
So he had the foresight to realize that these are extremely interesting problems.

211
00:16:01,408 --> 00:16:05,424
These are computer science problems essentially. How do we test if a number is prime?

212
00:16:05,424 --> 00:16:09,856
How do we factor a number if it's not a prime, if it's a composite?

213
00:16:09,856 --> 00:16:13,925
And already Gauss realized that these are extremely extremely important and interesting problems,

214
00:16:13,925 --> 00:16:19,208
and now, these days, these problems are actually used on the Web all over the place.

215
00:16:19,208 --> 00:16:24,175
So let's see. So, in fact, testing if a number is prime has been completely solved;

216
00:16:24,175 --> 00:16:29,024
we now know completely how to do it, using, efficiently using a randomized algorithm,

217
00:16:29,024 --> 00:16:31,793
and we even know how to do it using a deterministic algorithm.

218
00:16:31,793 --> 00:16:35,675
Factoring numbers, factoring composites into their prime factors,

219
00:16:35,675 --> 00:16:39,542
is still believed to be a difficult problem. I would encourage you actually to think about it.

220
00:16:39,542 --> 00:16:42,875
It's a wonderful problem to think about. If any of you can solve it,

221
00:16:42,875 --> 00:16:47,208
if any of you can come up with an algorithm to factor composites into prime factors,

222
00:16:47,208 --> 00:16:51,724
again, as I said, it's instant fame in the crypto world, and it would have tremendous impact

223
00:16:51,724 --> 00:16:56,657
on security of the Web in general. So it's a fun problem to think about.

224
00:16:56,657 --> 00:16:59,342
Let me tell you what's known about the problem of factoring.

225
00:16:59,342 --> 00:17:02,624
So the best algorithm that we have is called the number field sieve.

226
00:17:02,624 --> 00:17:07,764
Again, its running time is one of these exponentials, but a cube root of an exponential,

227
00:17:07,764 --> 00:17:13,042
which is why the composite has to be quite large for the problem to be difficult.

228
00:17:13,042 --> 00:17:18,657
Although the current world record is really just factoring a 768-bit number.

229
00:17:18,657 --> 00:17:24,008
This is called the RSA-768 number, it's a challenge number that was recently factored.

230
00:17:24,008 --> 00:17:28,842
The number is about 200 digits, and already factoring this number took an enormous amount of work.

231
00:17:28,842 --> 00:17:34,265
It took about two years on hundreds of machines, and finally they were able to factor this number.

232
00:17:34,265 --> 00:17:39,214
And the estimate is that actually factoring a 1024-bit number is about 1000 times harder

233
00:17:39,214 --> 00:17:45,102
than factoring RSA-768, so instead of 2 years, it would take two thousand years

234
00:17:45,102 --> 00:17:50,064
but of course computers are getting faster, we have more cores at our disposal,

235
00:17:50,064 --> 00:17:55,332
we have more computers, and so this factor of 1000, assuming Moore's Law and so on,

236
00:17:55,332 --> 00:17:59,039
really just means a decade—you know, computers get faster by about a factor of

237
00:17:59,039 --> 00:18:02,308
1000 every decade, so it's very likely that within the next decade,

238
00:18:02,308 --> 00:18:07,475
we'll see a factorization of a 1024-bit number, which would be the end of 1024 bits

239
00:18:07,475 --> 00:18:11,630
being used for public-key cryptography.

240
00:18:11,630 --> 00:18:16,026
So that's the state of the art in the factoring world, and this concludes this module.

241
00:18:16,026 --> 00:18:19,392
I'll mention that if you want to read more about any of the topics that we discussed,

242
00:18:19,392 --> 00:18:23,474
there is a good book on the Internet, it's a free book that you can download,

243
00:18:23,474 --> 00:18:27,109
written by Victor Shoup, and in particular, the topics that we discussed

244
00:18:27,109 --> 00:18:30,375
are covered in chapters 1 to 4, 11, and 12.

245
00:18:30,375 --> 00:18:33,557
So I would encourage you to take a look at that, and hopefully that will help

246
00:18:33,557 --> 00:18:35,993
with understanding the material.

247
00:18:35,993 --> 99:59:59,000
Next week, we'll start building cryptosystems using the topics we just learned about.
