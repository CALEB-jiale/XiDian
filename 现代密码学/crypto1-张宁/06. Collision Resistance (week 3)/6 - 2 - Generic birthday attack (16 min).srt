1
00:00:02,094 --> 00:00:04,189
The next thing I want to do is show you
the general attack on collision resistant

2
00:00:04,189 --> 00:00:08,020
hash functions. If you remember when we
talked about block cyphers. We saw a

3
00:00:08,020 --> 00:00:12,209
general attack on block cyphers which we
called exhaustive search. And that attack

4
00:00:12,209 --> 00:00:16,041
forced the key size for a block cypher to
be 128 bits or more. Similarly on

5
00:00:16,041 --> 00:00:20,128
collision resistance there is a general
attack called the birthday attack which

6
00:00:20,128 --> 00:00:24,317
forces the output of collision resistant
hash functions to be more than a certain

7
00:00:24,317 --> 00:00:28,506
bound. So let me show you the attack and
we will see what those bounds come out to

8
00:00:28,506 --> 00:00:32,822
be. So here's the general attack that can
work on arbitrary collision resistant hash

9
00:00:32,822 --> 00:00:36,933
functions. So here we have our collision
resistant hash functions, supposedly, but

10
00:00:36,933 --> 00:00:40,890
lets suppose that it outputs N bit values.
In other words, the output space is

11
00:00:40,890 --> 00:00:44,641
roughly of size two to the N. Now, the
message space is gonna be much, much

12
00:00:44,641 --> 00:00:48,650
larger than N bits. Let's just say that
the messages that are being hashed are

13
00:00:48,650 --> 00:00:53,070
say, you know, a hundred times N bits. I
wanna show you an algorithm that can find

14
00:00:53,070 --> 00:00:57,849
the collision for this hash function H in
time roughly two to the N over two. Okay,

15
00:00:57,849 --> 00:01:02,205
so roughly the square root of the size of
the outputs space. So here's how the

16
00:01:02,205 --> 00:01:06,730
algorithms gonna work: what we'll do is
we'll choose random two to the N over two

17
00:01:06,730 --> 00:01:10,974
messages in our message space that's
called an M-one to M-two to the N over

18
00:01:10,974 --> 00:01:15,219
two. Now because the messages themselves
are much bigger than N bits, they're

19
00:01:15,219 --> 00:01:19,576
hundred times N bits, it's very likely
that all these messages are distinct. So

20
00:01:19,576 --> 00:01:24,156
they'll be distinct with high probability.
But for each one of these messages we're

21
00:01:24,156 --> 00:01:28,723
gonna apply the hash function and obtain
the tag T sub I. So this is of course the

22
00:01:28,723 --> 00:01:33,372
T sub I's are N-bit long strings. And now
we're gonna look for a collision among the

23
00:01:33,372 --> 00:01:37,791
T sub I's. In other words, we're gonna
find an I and a J such that T sub I equals

24
00:01:37,791 --> 00:01:42,528
to T sub J. And once we've done that we've
basically found the collision because, as

25
00:01:42,528 --> 00:01:47,037
we said, with very high probability, M-I
is not equal to M-J. But the hash of M-I

26
00:01:47,037 --> 00:01:51,774
is equal to the hash of M-J and therefore
we found the collision on the function H.

27
00:01:51,774 --> 00:01:56,112
Now if it so happens that we looked
through all the two to the N over two T

28
00:01:56,112 --> 00:02:00,849
sub I's and we don't find the collision,
we go back to step one and try another set

29
00:02:00,849 --> 00:02:05,167
of two to the N over two messages. So the
question is how well will this work, in

30
00:02:05,167 --> 00:02:09,301
other words how many times do we have to
iterate this process until we actually

31
00:02:09,301 --> 00:02:13,486
find the collision? And I wanna show you
that in fact the number of iterations is

32
00:02:13,486 --> 00:02:17,827
gonna be very, very small which means that
this algorithm will find the collision in

33
00:02:17,827 --> 00:02:22,215
time that's roughly proportional two to
the N over two. So to analyze this type of

34
00:02:22,215 --> 00:02:26,853
attack, I have to tell you a little bit
about the birthday paradox. I imagine some

35
00:02:26,853 --> 00:02:30,862
of you have already heard about the
birthday paradox. Here stated as a

36
00:02:30,862 --> 00:02:35,213
theorem, and I wanna prove it to you
because everybody should see a proof of

37
00:02:35,213 --> 00:02:39,679
the birthday paradox at least once in
their lives. So here it is, so imagine we

38
00:02:39,679 --> 00:02:44,322
have N random variables R-one to R-N in
the interval one to B. And the only thing

39
00:02:44,322 --> 00:02:48,462
I'm gonna assume about them is that
they're actually independent of one

40
00:02:48,462 --> 00:02:52,948
another. That's crucial that these N
samples R-one to R-N in this interval are

41
00:02:52,948 --> 00:02:57,606
independent of one another. And they also
happen to be distributed identically. So

42
00:02:57,606 --> 00:03:02,149
for example, they might all be uniform in
the interval one to B, but again these

43
00:03:02,149 --> 00:03:06,806
would be independently uniform variables.
Now it so happens that if we set N to B

44
00:03:06,806 --> 00:03:11,637
about the square root of B, in other words
if we sample roughly the square root of B

45
00:03:11,637 --> 00:03:16,646
samples from the interval one to B, And to
be precise, it's one point two times the

46
00:03:16,646 --> 00:03:21,501
square root of B. Then the probability
that two of those samples will be the same

47
00:03:21,501 --> 00:03:25,576
is at least a half. Okay, then it turns
out in fact the uniform distribution is

48
00:03:25,576 --> 00:03:29,557
the worst case for the birthday paradox.
In other words, if the distribution from

49
00:03:29,557 --> 00:03:33,340
which the R-I's are sampled from is
non-uniform, that in fact fewer than one

50
00:03:33,340 --> 00:03:36,724
point two times the square root of B
samples are needed. The uniform

51
00:03:36,724 --> 00:03:40,357
distribution is the worst case. So we're
gonna prove this for the uniform

52
00:03:40,357 --> 00:03:44,288
distribution and that basically also
proves it for all other distributions. But

53
00:03:44,288 --> 00:03:48,320
the proof that I wanna show you here will
hold just for the uniform distribution.

54
00:03:48,320 --> 00:03:53,260
Okay, so let's do the proof that's
actually not difficult at all. So we're

55
00:03:53,260 --> 00:03:58,810
asking what is the probability that there
exists an I that is not equal to J such

56
00:03:58,810 --> 00:04:04,089
that RI is equal to RJ. Well, let's negate
that so it's basically one minus the

57
00:04:04,089 --> 00:04:09,638
probability that for all I not equal to J
we have that RI is not equal to RJ. This

58
00:04:09,638 --> 00:04:15,133
basically means that no collision occurred
among the N samples that we chose. Well

59
00:04:15,133 --> 00:04:19,330
let's try to write this out more
precisely. Well we're gonna write this as

60
00:04:19,330 --> 00:04:23,924
one minus. And now when we choose R-one,
basically it's the first one we choose so

61
00:04:23,924 --> 00:04:28,462
it's not gonna collide with anything. But
now let's look at what happens when we

62
00:04:28,462 --> 00:04:32,829
choose R-two, when we choose R-two, lemme
ask you, what is the probability that

63
00:04:32,829 --> 00:04:38,390
R-two. Does not collide with R-one. Well,
R-one takes one slot so there are B minus

64
00:04:38,390 --> 00:04:44,027
one slots that if R-two falls into it's
not gonna collide with R-one. So in other

65
00:04:44,027 --> 00:04:49,665
words the probability that R-two does not
collide with R-one is B minus one slot

66
00:04:49,665 --> 00:04:54,604
divided by all B possible slots.
Similarly, when we pick R-three What is

67
00:04:54,604 --> 00:05:00,057
the probability that R-three does not
collide with either R-one or R-two? Again,

68
00:05:00,057 --> 00:05:05,425
R-one and R-two take up two slots. And so
there are B minus two slots that remain

69
00:05:05,425 --> 00:05:10,860
for R-three if it falls into either one of
those B minus two slots it's not gonna

70
00:05:10,860 --> 00:05:16,409
collide with either R-one or R-two. So I
imagine you see the pattern now, so R-four

71
00:05:16,409 --> 00:05:21,838
it's probability of not colliding with
R-one, R-two, or R-three is B minus three

72
00:05:21,838 --> 00:05:26,786
over B. And so on and so forth until we
get to the very last R-N and the

73
00:05:26,786 --> 00:05:32,215
probability that R-N does not collide with
the previous R-I's, well, there are N

74
00:05:32,215 --> 00:05:37,644
minus one slots taken up by the previous
R-I's. So, if R-N falls into any of the

75
00:05:37,644 --> 00:05:42,561
remaining B minus N plus one slots It's
not gonna collide with any of the previous

76
00:05:42,561 --> 00:05:46,798
R-one to R-N minus one. Now you notice
that the reason I was able to multiply all

77
00:05:46,798 --> 00:05:51,192
these probabilities is exactly because the
R-I's are all independent of one another.

78
00:05:51,192 --> 00:05:55,567
So it's crucial for the step That the
R-I's are independent. So let me rewrite

79
00:05:55,567 --> 00:06:00,559
this expression a little bit. Let me write
it as one minus the product of I goes to N

80
00:06:00,559 --> 00:06:05,533
minus one of one minus I over B. Okay. All
I did is I just rewrote this as a big

81
00:06:05,533 --> 00:06:10,264
product as opposed to writing the terms
individually. So now I'm gonna use the

82
00:06:10,264 --> 00:06:15,358
standard inequality that says that for any
positive X, one minus X is less than E to

83
00:06:15,358 --> 00:06:20,271
the minus X. And that's actually easy to
see because E to the minus X, if you look

84
00:06:20,271 --> 00:06:25,123
at it's Taylor expansion, is one minus X
plus X squared over two minus and so on

85
00:06:25,123 --> 00:06:29,915
and so forth. And so you can see that
we're basically ignoring this latter part

86
00:06:29,915 --> 00:06:34,970
of the Taylor expansion, which happens to
be positive and as a result the left side

87
00:06:34,970 --> 00:06:39,644
is gonna be smaller than the right-hand
side. Okay, so let's plug this inequality

88
00:06:39,644 --> 00:06:44,716
in, and what do we get? We get that this
is greater than one minus the product of I

89
00:06:44,716 --> 00:06:49,988
goes from one to N minus one of E to the
minus I over B okay, simply plugged in X

90
00:06:49,988 --> 00:06:54,980
equals I over B for each one of those
terms. And the next thing about

91
00:06:54,980 --> 00:07:00,985
exponentials is that we multiply them, the
exponents add. As a result this is simply

92
00:07:00,985 --> 00:07:06,773
equal to one minus E to the power of, here
let me take the one over B out of the

93
00:07:06,773 --> 00:07:12,455
parentheses, sum of I goes from one to N
minus one of I. Okay. So, all I did was I

94
00:07:12,455 --> 00:07:17,594
took the minus one over B out of the
parentheses and we're left with simple sum

95
00:07:17,594 --> 00:07:22,423
of one to N minus one. And so the sum of
the integers from N to N minus one is

96
00:07:22,423 --> 00:07:27,624
simply N times N minus one over two which
it can bound by N squared over two. And so

97
00:07:27,624 --> 00:07:32,638
really what I get at the end here is one
minus E to the power of minus N squared

98
00:07:32,638 --> 00:07:38,448
over two B. Okay, I literally downed it to
sum here by N squared over two. Okay, very

99
00:07:38,448 --> 00:07:44,226
good. So now what do we do about N squared
over two B? Well, we can derive exactly

100
00:07:44,226 --> 00:07:49,860
what N squared over two B is from the
relationship here. So if you think about

101
00:07:49,860 --> 00:07:55,493
it, let's look at N squared over two.
Well, N squared over two is 1.2 squared

102
00:07:55,493 --> 00:08:01,127
over two. 1.2 squared is 1.44 divided by
two is .72 times the square root of B

103
00:08:01,127 --> 00:08:08,629
squared which is B. Okay so N squared over
two is .72B, and as a result, N squared

104
00:08:08,629 --> 00:08:16,042
over 2B is just .72. So we get 1-E, which
is a power of minus 0.72. Well so now you

105
00:08:16,042 --> 00:08:20,457
just plug this in to your calculator and
you get 0.53, which as far as i know, is

106
00:08:20,457 --> 00:08:24,871
always bigger than F. So this proves the
Birthday Paradox and you notice that it

107
00:08:24,871 --> 00:08:29,285
was crucial to a string that the samples
are independent of one another, we only

108
00:08:29,285 --> 00:08:33,810
proved that for the uniform distribution.
But as i said it is actually fairly easy

109
00:08:33,810 --> 00:08:38,390
to argue now that any distribution that is
away from the uniform distribution will

110
00:08:38,390 --> 00:08:42,977
satisfy this with even a lower balance. So
if you have. 1.2 squared of B, the theorem

111
00:08:42,977 --> 00:08:47,245
will certainly hold for none uniform
distributions. The reason it is called a

112
00:08:47,245 --> 00:08:51,846
paradox is because it is very paradoxical
that the square root function grows very

113
00:08:51,846 --> 00:08:56,336
slowly. In particular if you try to apply
this to birth dates, so lets assume that

114
00:08:56,336 --> 00:09:00,771
we have a number of people in a room, and
lets assume that their birth dates are

115
00:09:00,771 --> 00:09:05,454
independent of one another and are uniform
in their interval one through 365. Then

116
00:09:05,454 --> 00:09:12,418
what the Birthday Paradox says is that we
need roughly 1.2 times the square root of

117
00:09:12,418 --> 00:09:17,098
365. Which i believe is something like 23,
which says we need roughly 23 people in a

118
00:09:17,098 --> 00:09:21,502
room, and then with probability one half,
two of them will actually have the same

119
00:09:21,502 --> 00:09:25,686
birth date. The reason it is called a
paradox is because the number 23 seems

120
00:09:25,686 --> 00:09:30,035
really small to people, and yet by this
theorem we just proved, with probability

121
00:09:30,035 --> 00:09:34,109
one half, there will be two people with
the same birth date. By the way the

122
00:09:34,109 --> 00:09:38,292
intuition for why this fact is true is
because really what the collision is

123
00:09:38,292 --> 00:09:42,861
counting is it is looking at all possible
pairs of people. And if you have a square

124
00:09:42,861 --> 00:09:47,627
root of B people, then there are square
root of B squared pairs. Roughly, Which is

125
00:09:47,627 --> 00:09:52,248
roughly B pairs total and so it's very
likely that each pair collides probability

126
00:09:52,248 --> 00:09:56,870
one over B and if you have B pairs, it's
likely that one of the pairs will collide.

127
00:09:56,870 --> 00:10:01,312
So hopefully this gives the intuition for
where the square root comes from. Its

128
00:10:01,312 --> 00:10:05,924
basically from the fact that if you have N
people in the room, there are N squared

129
00:10:05,924 --> 00:10:10,423
possible pairs. I should say by the way
that even though the Birthday Paradox is

130
00:10:10,423 --> 00:10:14,923
often applied to birth dates, birth dates
are actually not uniform at all. If you

131
00:10:14,923 --> 00:10:19,309
actually look at the birth dates of
people, you see that there is a very clear

132
00:10:19,309 --> 00:10:23,696
bias towards being born in September, and
for me bazaar reason there is also a

133
00:10:23,696 --> 00:10:27,984
biased towards being born on a Tuesday.
And so when we apply the birthday paradox

134
00:10:27,984 --> 00:10:31,975
to birthdays, in fact the actual bound is
going to be smaller than one minus two

135
00:10:31,975 --> 00:10:36,164
square root of B because we said that for
non even form distributions you need even

136
00:10:36,164 --> 00:10:40,230
fewer samples before you get a collision.
So let me show you how to graph the

137
00:10:40,230 --> 00:10:44,494
Birthday Paradox, its quite interesting
how it behaves. So here set B to be a

138
00:10:44,494 --> 00:10:49,039
million, in other words we are picking
random uniform samples in the range one to

139
00:10:49,039 --> 00:10:53,472
a million. And the X axis here, is the
number of samples that we are picking, and

140
00:10:53,472 --> 00:10:58,073
the Y axis, is the probability that we get
a collision among those N samples. So we

141
00:10:58,073 --> 00:11:02,170
see that the probability of one half
happens around 1.2 square root of B.

142
00:11:02,170 --> 00:11:06,486
Roughly twelve hundreds, 1.2 square root
of B. And you see that if we look at

143
00:11:06,486 --> 00:11:10,689
exactly the square root of B, the
probability of a collisions is around .4

144
00:11:10,689 --> 00:11:14,835
or .41. And you notice that the
probability goes up to one extremely fast.

145
00:11:14,835 --> 00:11:19,209
For example, already at roughly two square
root of B, but the probability of a

146
00:11:19,209 --> 00:11:23,355
collision is already 90%. Similarly, when
we go bellow square root of B, the

147
00:11:23,355 --> 00:11:27,632
probability of a collision very, very
quickly drops to zero. Okay, so there is

148
00:11:27,632 --> 00:11:32,199
kind of a threshold phenomena around
square root of B, where the probability of

149
00:11:32,199 --> 00:11:36,767
a collision goes to one very quickly,
above square root of B drops to zero very

150
00:11:36,767 --> 00:11:41,507
quickly below square root of B. So now we
can analyze are attack algorithms, so let

151
00:11:41,507 --> 00:11:45,843
me remind you, here we chose, two to the
interval two random elements in the

152
00:11:45,843 --> 00:11:51,089
message space, we hashed them. And so we
started off with a random distribution in

153
00:11:51,089 --> 00:11:56,306
the message base, after we hashed them, we
end up with some distribution, this

154
00:11:56,306 --> 00:12:01,523
distribution over tags might note be
uniform, but we don't care, the point is

155
00:12:01,523 --> 00:12:07,289
that all these tags T1 to T2 to the N over
two, are independent of one another. If we

156
00:12:07,289 --> 00:12:11,941
choose. Two to the N over two or 1.2 to
the N over two, tags, the probability that

157
00:12:11,941 --> 00:12:16,285
the collision will exist is roughly one
half. So let me ask you then, in that

158
00:12:16,285 --> 00:12:21,028
case, how many times do we have to iterate
this algorithm before we actually find a

159
00:12:21,028 --> 00:12:25,688
collision? Well then since each iteration
is going to find a collision with

160
00:12:25,688 --> 00:12:30,202
probability one half, we have to iterate
about two times in expectation. And as a

161
00:12:30,202 --> 00:12:34,547
result the running time of this algorithm
is basically two to the N over two

162
00:12:34,547 --> 00:12:39,251
evaluations of the hash function. Okay so
notice also this algorithm takes a lot of

163
00:12:39,251 --> 00:12:43,652
space but we're gonna ignore the space
issue and we're just gonna focus on the

164
00:12:43,652 --> 00:12:47,831
running time. Okay so this is kinda cool,
this says that if your hash

165
00:12:47,831 --> 00:12:52,400
function outputs N-bits outputs
there will always be an attack algorithm

166
00:12:52,400 --> 00:12:56,634
that runs in time two to the N over two.
So for example if we output 128 big

167
00:12:56,634 --> 00:13:01,655
outputs Then a collision could be found in
time two to the sixty four, which is not considered

168
00:13:01,655 --> 00:13:05,989
sufficiently secure. Okay, this is why
collision resistant hash functions,

169
00:13:05,989 --> 00:13:10,564
generally are not going to output 128
bits. So let me show you some examples.

170
00:13:10,564 --> 00:13:15,019
The first three are actually federal
standards, SHA-1, SHA-256, and SHA-512

171
00:13:15,019 --> 00:13:19,834
and the fourth one is an example from
the designers of AES, called Whirlpool,

172
00:13:19,834 --> 00:13:24,650
and so you can see SHA-1 outputs 160
bits and as a result there is a generic

173
00:13:24,650 --> 00:13:28,835
attack on it that runs on
time two to the eighty. SHA-256 outputs 256

174
00:13:28,835 --> 00:13:33,496
bits so the generic attack will run
in time two to the 128 and so on and so

175
00:13:33,496 --> 00:13:37,887
forth. I also listed the speed of these
algorithms and you notice that the bigger

176
00:13:37,887 --> 00:13:41,790
the block size actually the slower the
algorithm is [and?] so there's a

177
00:13:41,790 --> 00:13:46,127
performance penalty but nevertheless
there's quite a bit of benefit in terms of

178
00:13:46,127 --> 00:13:50,213
security. Now you notice the SHA
function is actually greyed out. The

179
00:13:50,213 --> 00:13:53,970
SHA function although nobody has
found collisions for SHA-1 yet

180
00:13:53,970 --> 00:13:58,133
It is still recommended that in a new
project, and hopefully programing projects

181
00:13:58,133 --> 00:14:02,088
in this class, you don't use SHA-1,
instead you use SHA-256. In particular

182
00:14:02,088 --> 00:14:06,459
there is actually a theoretical collision
finder on SHA-1 that works in time two

183
00:14:06,459 --> 00:14:10,727
to the 51. So it is probably just a matter
of time until someone finds a collision

184
00:14:10,727 --> 00:14:14,994
for SHA-1, and just kills altogether,
but the current advice is that SHA-1 is

185
00:14:14,994 --> 00:14:19,261
still a collision resistant hash function
because nobody has found collisions for

186
00:14:19,261 --> 00:14:23,164
it, but it is probably just a matter of
time, just a few months, or few years,

187
00:14:23,164 --> 00:14:27,397
until a collision is found. It is a result
a new product and new projects SHA-1

188
00:14:27,397 --> 00:14:31,199
should not be used and only use
SHA-256 or if you wanna be even

189
00:14:31,199 --> 00:14:34,546
more cautious then use SHA-512. So this is the end of this

190
00:14:34,546 --> 00:14:37,322
segment, and now we are going to turn
building collision resistant hash
