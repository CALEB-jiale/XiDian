1
00:00:00,000 --> 00:00:04,473
多年以来许多原始密码学构造被发现是不可靠的

2
00:00:04,473 --> 00:00:08,560
因此，使得现代密码学成为一门严谨的科学

3
00:00:08,560 --> 00:00:13,033
它的解释总是伴随着对安全性的证明

4
00:00:13,033 --> 00:00:17,341
对安全性的描述是基于离散概率
在此节和下一小节中

5
00:00:17,341 --> 00:00:21,538
我将简要的回顾一下离散概率
在我提到的这篇维基教科书里的文章

6
00:00:21,538 --> 00:00:26,196
有很长的一段介绍
离散概率总是

7
00:00:26,196 --> 00:00:31,573
用全集定义，我将其用U来表示
并且定义它为一个有穷集合

8
00:00:31,573 --> 00:00:36,630
事实上，我们的全集很常见的可能就是

9
00:00:36,630 --> 00:00:41,944
所有n位字符串的集合
这里用01的N次集合来表示

10
00:00:41,944 --> 00:00:47,193
比如0、1集合的平方是两位字符串

11
00:00:47,193 --> 00:00:52,207
00，01，10，11的集合

12
00:00:52,207 --> 00:00:56,991
所以这个集合里有4个元素
一般来说，0、1的N次集合

13
00:00:56,991 --> 00:01:01,809
有2^n个元素
此集合U的概率分布

14
00:01:01,809 --> 00:01:07,240
可以仅用函数P来表示

15
00:01:07,240 --> 00:01:12,470
该函数为全局中的每一个元素赋一个0到1之间的值

16
00:01:12,470 --> 00:01:17,567
这个值就叫做此集合特定元素的权重或概率

17
00:01:17,567 --> 00:01:22,663
现在对函数P只有一个必要条件

18
00:01:22,663 --> 00:01:27,830
就是所有权重之和为1

19
00:01:27,830 --> 00:01:33,573
也就是说，如果我把此集合内每个元素X的概率相加

20
00:01:33,573 --> 00:01:38,911
最终会得到1。让我们看一个非常简单的例子
全体二位字符串

21
00:01:38,911 --> 00:01:44,249
00，01,10,11
你可以考虑如下概率分布

22
00:01:44,249 --> 00:01:49,452
例如，P(00)=1/2

23
00:01:49,452 --> 00:01:54,267
P(01)=1/8

24
00:01:54,267 --> 00:01:59,367
P(10)=1/4
P(11)=1/8

25
00:01:59,367 --> 00:02:04,343
可以看到如果把这些数字
的和加起来那么结果为1

26
00:02:04,343 --> 00:02:09,380
也就是概率P符合概率分布条件

27
00:02:09,380 --> 00:02:14,542
现在这些数字的意思是，如果我从这个概率分布中取样

28
00:02:14,542 --> 00:02:19,766
那么我得到字符串00的概率是1/2
01的概率是1/8,并以此类推

29
00:02:19,766 --> 00:02:24,612
所以现在我们理解了概率分布的含义

30
00:02:24,612 --> 00:02:29,025
就让我们来看一下两个概率分布的经典例子

31
00:02:29,025 --> 00:02:33,437
第一个是均匀分布

32
00:02:33,437 --> 00:02:38,350
均匀分布为集合中的每一个元素
分配完全一样的权重

33
00:02:38,350 --> 00:02:43,569
记|U|为总体U的大小
即总体的元素个数

34
00:02:43,569 --> 00:02:48,665
既然我们希望权重的总和为1
且每个元素的权重相同

35
00:02:48,665 --> 00:02:53,449
这意味着总体中的每个元素X

36
00:02:53,449 --> 00:02:58,622
我们为之赋以1/U的概率
如果我们再详细地看一下例子

37
00:02:58,622 --> 00:03:03,642
均匀分布和两位字符串的集合

38
00:03:03,642 --> 00:03:09,048
我们将会简单地给每一个字符分配1/4的权重

39
00:03:09,048 --> 00:03:13,875
显然所有权重的和加起来为1

40
00:03:13,875 --> 00:03:19,217
这意味着如果我从这个分布中随机取样

41
00:03:19,217 --> 00:03:24,687
我将会得到所有两位字符串的均匀样本
因此所有这些2位字符串在此概率分布中

42
00:03:24,687 --> 00:03:29,848
被取样的概率相等
另一个非常常见的分布是

43
00:03:30,051 --> 00:03:35,734
点分布
点分布的主要做法是

44
00:03:35,734 --> 00:03:41,145
将所有的权重分配到一个点X0上

45
00:03:41,145 --> 00:03:46,422
我们将所有权重都赋给X0，自然在此总体中

46
00:03:46,422 --> 00:03:51,937
我们将其他点的权重赋0
另外我想解释一下

47
00:03:52,357 --> 00:03:57,953
这个倒着的A表示任意，所以这一切说明了，

48
00:03:57,953 --> 00:04:02,963
所有不为X0的X的概率为0

49
00:04:02,963 --> 00:04:08,124
再一次回到我们的例子，
比如点分布中

50
00:04:08,124 --> 00:04:13,352
将概率全部只分给字符串1-0
即P(10)=1

51
00:04:13,352 --> 00:04:19,184
而其他的字符串概率均为0
所以如果我从这个分布中取样

52
00:04:19,184 --> 00:04:24,881
我将总保证能得到字符串10
而不会得到其它的字符串

53
00:04:24,881 --> 00:04:29,556
现在我们知道分配是什么了

54
00:04:29,556 --> 00:04:34,196
我还想再说最后一点
可以这样做的原因是因为总体U为有限集

55
00:04:34,196 --> 00:04:38,355
所以我们可以写出U中每一个元素分配到的权重

56
00:04:38,355 --> 00:04:43,236
并且可以用一个向量表示整个分布

57
00:04:43,236 --> 00:04:47,881
比如说，如果你观察所有的3位字符串

58
00:04:47,881 --> 00:04:52,985
我们可以逐个写下

59
00:04:52,985 --> 00:04:58,089
P(000)、P(001)等等

60
00:04:58,089 --> 00:05:03,255
我们可以把这些概率写成向量形式

61
00:05:03,255 --> 00:05:08,484
这样的向量是8维的三位字符串有8个

62
00:05:08,484 --> 00:05:13,650
基本上整个分布用这8个实数的向量表示

63
00:05:13,650 --> 00:05:18,874
实数的范围都是0到1。
下一步我要做的是

64
00:05:18,874 --> 00:05:24,412
定义事件的概念。
考虑我们整体的子集A

65
00:05:24,412 --> 00:05:30,086
定义子集A的概率为A集合中所有元素的权重

66
00:05:30,086 --> 00:05:35,419
换句话说，我将把A中X的概率求和

67
00:05:35,419 --> 00:05:40,038
因为整体的权重和应为1

68
00:05:40,038 --> 00:05:44,278
这意味着如果求和

69
00:05:44,278 --> 00:05:48,517
整体的概率应为1

70
00:05:48,517 --> 00:05:52,813
如果我们观察整体的一个子集的概率，我们会得到一个介于0和1之间的数

71
00:05:52,813 --> 00:05:57,683
我们说集合A的概率是一个介于0和1之间的和

72
00:05:57,683 --> 00:06:02,265
那么整体的子集A就叫做一个事件

73
00:06:02,265 --> 00:06:06,839
集合A的概率就叫做这一事件的的概率

74
00:06:06,839 --> 00:06:12,714
让我们看一个简单的例子，假定我们

75
00:06:12,714 --> 00:06:19,135
有集合U，它包含所有8位字符串，好吧？

76
00:06:19,135 --> 00:06:26,057
所以集合的大小是256，因为它有256个8位字符串上

77
00:06:26,057 --> 00:06:32,352
我们本质是在看所有可能的256个字节值，
现在我们定义以下事件

78
00:06:32,352 --> 00:06:37,677
这一事件同样有8位

79
00:06:37,677 --> 00:06:44,038
并且其最低两位为11

80
00:06:44,038 --> 00:06:50,324
比如01011010，
它是整体的一个元素

81
00:06:50,324 --> 00:06:56,132
但它不在集合A中，
如果我们把这个0改为1

82
00:06:56,132 --> 00:07:01,275
它就是集合A中的元素，
现在我们来看看全局U上的均匀分布

83
00:07:01,275 --> 00:07:05,990
现在我问你事件A的概率是多少？

84
00:07:05,990 --> 00:07:10,565
当我们随机选择一个字节

85
00:07:10,565 --> 00:07:16,947
字节最后两位正好是11的概率是多少

86
00:07:16,947 --> 00:07:23,435
结果是1/4，找的答案并不难

87
00:07:23,435 --> 00:07:29,381
256个字符串中，
有64个这样的字节

88
00:07:29,381 --> 00:07:34,118
也就是1/4的字符串以11结尾
考虑到均匀分布

89
00:07:34,118 --> 00:07:38,722
每个字符串的概率是1/|U|

90
00:07:38,722 --> 00:07:43,213
即1/256

91
00:07:43,213 --> 00:07:47,817
64个元素每个权重1/256，一共是1/4

92
00:07:47,817 --> 00:07:52,764
这就是事件A的概率，
事件概率有一个简单的范围

93
00:07:52,764 --> 00:07:57,987
叫做并集上界
假设我们有两个事件A1和A2

94
00:07:57,987 --> 00:08:03,135
它们都是全集U的子集，我们想知道

95
00:08:03,135 --> 00:08:07,564
事件A1发生或者事件A2发生的概率，即P(A1∪A2)

96
00:08:07,564 --> 00:08:12,113
符号∪表示两个集合的并集

97
00:08:12,113 --> 00:08:17,081
并集上界指出了

98
00:08:17,081 --> 00:08:22,041
P(A1∪A2)≤P(A1)+P(A2)

99
00:08:22,041 --> 00:08:26,560
这是显而易见的，在这幅图中

100
00:08:26,560 --> 00:08:31,022
观察这两个概率的和

101
00:08:31,022 --> 00:08:35,483
它们分别是A1中元素概率的和
以及A2中元素概率的和

102
00:08:35,483 --> 00:08:40,002
你会意识到我们好像把两个
集合重叠部分的元素加了两次

103
00:08:40,002 --> 00:08:44,966
使得在右边求和时算了两次

104
00:08:44,966 --> 00:08:50,351
结果使得这两个概率的和大于等于P(A1∪A2)

105
00:08:50,351 --> 00:08:56,102
这就是经典的并集上界定义

106
00:08:56,102 --> 00:09:01,169
如果两个事件不相交，
换句话说它们的交集为空

107
00:09:01,169 --> 00:09:06,792
那么这个式子就变成

108
00:09:06,792 --> 00:09:12,553
P(A1∪A2)=P(A1)+P(A2)

109
00:09:12,553 --> 00:09:18,637
怎么样？我们将在整门课使用这些结论

110
00:09:18,637 --> 00:09:24,378
让我们理清一下，这个不等关系一直存在
除非两个事件不相交，

111
00:09:24,378 --> 00:09:30,258
那时候取等号。让我们看一个简单的例子

112
00:09:30,258 --> 00:09:36,265
事件A1是所有以11结尾的n位字符串的集合

113
00:09:36,265 --> 00:09:42,778
假设A2是所有以11开头的n位字符串

114
00:09:42,778 --> 00:09:47,607
n设定为H或某个大数，
问事件A1或事件A2发生的概率是多少？

115
00:09:47,607 --> 00:09:51,729
换句话说，

116
00:09:51,729 --> 00:09:56,205
如果在全体U中均匀取样，
最后2位为11

117
00:09:56,205 --> 00:10:00,916
或者最前2位是11的概率是多少？

118
00:10:00,916 --> 00:10:05,626
我们说这个概率记为P(A1∪A2)

119
00:10:05,626 --> 00:10:10,279
在前面我们知道每一事件的概率是1/4

120
00:10:10,279 --> 00:10:14,813
因此根据并集上限

121
00:10:14,813 --> 00:10:19,018
“或”的概率为P(A1)+P(A2)

122
00:10:19,018 --> 00:10:23,763
即1/4+1/4,我们这就证明了

123
00:10:23,763 --> 00:10:28,448
最前2位是11的概率
或者最后两位是11的概率

124
00:10:28,448 --> 00:10:33,198
小于等于1/2，
这是一个简单的例子

125
00:10:33,198 --> 00:10:37,888
说明了我们如何用并集上界来界定两个事件中一个事件发生的概率

126
00:10:37,888 --> 00:10:41,842
下一个我们需要定义的概念是随机变量

127
00:10:41,842 --> 00:10:46,520
随机变量是比较直观的对象

128
00:10:46,520 --> 00:10:51,197
但令人遗憾的是随机变量的正式定义不好理解

129
00:10:51,197 --> 00:10:55,702
所以我将要做的是，
给出一个例子，并希望它足够直观

130
00:10:55,702 --> 00:11:00,264
形式上定义随机变量为X，
它是从全体到某个集合V的函数

131
00:11:00,264 --> 00:11:05,115
集合V就是随机变量取值的地方

132
00:11:05,115 --> 00:11:09,991
让我们看一个具体的例子。
假设我们有一个随机变量X

133
00:11:09,991 --> 00:11:15,185
这个随机变量映射到集合01中

134
00:11:15,185 --> 00:11:20,183
所以这个随机变量的值为0或1，
是的，1位，基本的。

135
00:11:20,183 --> 00:11:25,504
现在，这个随机变量映射到我们的全集，
也就是所有二元字符串的定义域[0,1]^n

136
00:11:25,504 --> 00:11:30,112
它是怎么做的？
从全体中给出一个具体样本

137
00:11:30,112 --> 00:11:34,775
一个特别的n位字符串y。
而随机变量所做的就是简单得输出了

138
00:11:34,775 --> 00:11:39,525
y的最低有效位。
这就是整个随机变量

139
00:11:39,525 --> 00:11:44,093
现在我要问，
假设有一个在集合[0,1]^n上的随机分布

140
00:11:44,093 --> 00:11:48,108
问这个随机变量输出0的概率是多少？

141
00:11:48,108 --> 00:11:52,352
以及输出1的概率是多少？

142
00:11:52,352 --> 00:11:56,920
你可以看到答案分别是1/2,1/2.
让我们来推导下为什么会这样

143
00:11:56,920 --> 00:12:01,151
这张图展示了全体的情况

144
00:12:01,151 --> 00:12:05,719
和可能的输出空间。
所以变量可能的输出是0或1

145
00:12:05,719 --> 00:12:10,119
当这儿有一个变量输出0，
这里有一个变量输出0，

146
00:12:10,119 --> 00:12:14,801
当全集中的样本出现时，
即出现最低有效位。

147
00:12:14,801 --> 00:12:19,111
变量为1时总体中的样本

148
00:12:19,111 --> 00:12:23,723
最低有效位为1。
如果随机均匀选择字符串

149
00:12:23,723 --> 00:12:28,516
那么我们选到以0结尾的字符串的概率为1/2

150
00:12:28,516 --> 00:12:33,250
随机变量结果为0的概率也为1/2

151
00:12:33,250 --> 00:12:37,305
同样的如果我们随机选取一个n位字符串

152
00:12:37,305 --> 00:12:41,627
最后一位为1的概率也是1/2

153
00:12:41,627 --> 00:12:45,682
我们说随机变量结果为1的概率也是1/2

154
00:12:45,682 --> 00:12:49,820
现在，在更一般的情况
如果我们有一个随机变量

155
00:12:49,820 --> 00:12:55,118
在一个确定集合V中取值，
这个随机变量实际上可以推出

156
00:12:55,118 --> 00:13:00,042
集合V的分布。这里我们以符号形式

157
00:13:00,042 --> 00:13:05,216
表示这个分布的意义。
不过这其实是很好解释的

158
00:13:05,216 --> 00:13:10,871
本质上它表示这个变量结果为V。
因为我们在全体中随机选取元素

159
00:13:10,871 --> 00:13:15,631
所以概率是相等，然后我们应用函数X

160
00:13:15,631 --> 00:13:20,648
问输出为v的可能性是多少？

161
00:13:20,648 --> 00:13:25,620
形式上说P(X=v)为我们在总体中随机取出一个元素

162
00:13:25,620 --> 00:13:30,411
在函数X的作用下

163
00:13:30,411 --> 00:13:35,024
结果落在v的原象中的概率。
如果这样不清楚，也不要紧

164
00:13:35,024 --> 00:13:39,516
你需要知道的是，
随机变量在特定的集合V中取值

165
00:13:39,516 --> 00:13:44,014
而且可以推导出集合V的概率分布

166
00:13:44,014 --> 00:13:48,902
有一个特别重要的随机变量叫均匀随机变量

167
00:13:48,902 --> 00:13:53,910
它基本上是如你期望的那样进行定义。
那么我们说U是某有限集

168
00:13:53,910 --> 00:13:58,557
比如所有N位二元字符串

169
00:13:58,557 --> 00:14:03,203
我们用R表示随机变量，从集合U均匀地取样

170
00:14:03,203 --> 00:14:08,109
用这个有点搞笑的箭头加上R表示，

171
00:14:08,109 --> 00:14:13,164
讲义上的随机变量R
是集合U上的均匀随机变量

172
00:14:13,164 --> 00:14:17,792
符号a∈U表示所有的元素a都在全集U里

173
00:14:17,792 --> 00:14:22,907
P(r=a)=1/|U|，如果你坚持使用

174
00:14:22,907 --> 00:14:27,901
均匀随机变量的正式定义，
这个也不那么重要

175
00:14:28,084 --> 00:14:33,017
但我想说从形式上均匀随机变量是恒等式

176
00:14:33,017 --> 00:14:38,341
也就是说 对所有R(x)=X (a∈U)，
只是为了确保这足够清楚

177
00:14:38,341 --> 00:14:43,716
我要问你们一个简单的问题。假设

178
00:14:43,716 --> 00:14:49,375
我们有一个2位字符串的均匀随机变量全体，
即集合为01, 10, 00, 11

179
00:14:49,375 --> 00:14:55,317
定义一个新的随机变量x，
表示将R的第1位和第2位相加

180
00:14:55,317 --> 00:15:01,117
即X=r1+r2，
R的第1位和第2位相加

181
00:15:01,117 --> 00:15:06,914
把这2位当做整数，
例如R=00，那么X=0+0=0

182
00:15:06,914 --> 00:15:13,400
所以我要问，P(x=2)是多少？

183
00:15:13,400 --> 00:15:19,289
不难看出答案是1/4,因为

184
00:15:19,289 --> 00:15:24,777
x=2的情况只有R=11

185
00:15:24,777 --> 00:15:29,930
但是R=11的概率只有1/4,
因为R是在所有2位字符串中均匀分布的

186
00:15:29,930 --> 00:15:34,409
最后一个我想在这一节定义的概念是

187
00:15:34,409 --> 00:15:38,629
随机算法，
我相信你们都熟悉确定性算法

188
00:15:38,629 --> 00:15:42,355
这些算法对特定的输入数据

189
00:15:42,355 --> 00:15:47,068
总是产生相同的输出，记为Y

190
00:15:47,068 --> 00:15:51,671
如果我们将算法在同样输入下运行一百遍，
我们总会得到同样的输出

191
00:15:51,671 --> 00:15:55,617
所以可以把确定算法看做一个函数

192
00:15:55,617 --> 00:16:00,056
给出一个确定输入数据M，
总会准确地产生同样的输出A(m)

193
00:16:00,056 --> 00:16:05,345
随机算法有点不同，在随机算法中

194
00:16:05,345 --> 00:16:11,197
依旧将取数据M作为输入，
不过还有一个隐形参数R

195
00:16:11,197 --> 00:16:16,770
R在每次运行算法的时候都会重新取样，特别的

196
00:16:16,770 --> 00:16:21,925
R是在所有N位字符串中均匀随机取样的

197
00:16:22,134 --> 00:16:26,716
现在的情况是每次我们在输入M下运行算法

198
00:16:26,716 --> 00:16:31,172
都会得到一个不同的输出，
因为每次的R都不一样

199
00:16:31,172 --> 00:16:35,044
所以我们第一次运行算法会得到一个输出

200
00:16:35,044 --> 00:16:39,128
第二次运行算法产生一个新R，
我们又会得到一个不同的输出

201
00:16:39,128 --> 00:16:43,530
第三次运行算法又会产生一个新R，我们又会得到另一个不同的输出

202
00:16:43,689 --> 00:16:48,742
以此类推。所以仔细思考随机算法，
其实就是

203
00:16:48,742 --> 00:16:53,689
定义一个随机变量。
对吧？给出一个

204
00:16:53,689 --> 00:16:59,201
特定输入信息M。
它就定义了一个随机变量

205
00:16:59,201 --> 00:17:04,533
给定输入M，
就得到了算法的可能输出。
206
00:17:04,533 --> 00:17:09,222
所以要记住的事情是每次运行随机算法，
它的输出都会变化

207
00:17:09,222 --> 00:17:14,085
事实上，算法本身定义了一个分布和所有可能输出的集合

208
00:17:14,085 --> 00:17:18,480
让我们看一个特定的例子，
假设我们有一个随机算法

209
00:17:18,480 --> 00:17:23,266
以M为输入，当然也有隐性输入

210
00:17:23,266 --> 00:17:27,533
也就是这个字符串，
用来使过程随机化

211
00:17:27,533 --> 00:17:32,838
现在这个算法要做的是以这个随机字符串为输入

212
00:17:32,838 --> 00:17:38,300
加密信息M。
所以这基本上定义了一个随机变量

213
00:17:38,300 --> 00:17:43,495
此随机变量取值于信息M的加密结果

214
00:17:43,495 --> 00:17:48,557
这个随机变量其实是定义在均匀密钥下

215
00:17:48,557 --> 00:17:53,532
信息M全部可能的加密结果上的概率分布。
所以重点要记住的是

216
00:17:53,532 --> 00:17:58,087
就算每次运行随机算法的时候

217
00:17:58,087 --> 00:18:02,219
输入可能总是相同的，你也将会得到一个不同的输出

218
00:18:02,219 --> 00:18:05,836
好了，这一节就结束了，我们将在下一节

219
00:18:05,836 --> 00:18:07,320
讨论更多关于离散概率的内容。【END】